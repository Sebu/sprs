\chapter{Overview}

\section{Problem}
Signal representation via linear combination of <> .
\section{signal representation}
approximate signals via combination of limited signal samples
Why?
signal analysis, compression, denoise etc.
\subsection{discrete signals}
\subsection{basis transformation}
\subsection{sparse codes/coding}
Idea: interpret the basis transforms as sparse linear combination of dictionary atoms
Benefit: decouple signal coding and dictionary design

\[
\underbrace{\begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}}_{signal} \approx \underbrace{\begin{pmatrix} d_1  d_2 \cdots d_n \end{pmatrix}}_{\textrm{dictionary}}
\underbrace{\begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_n \end{pmatrix}}_{\textrm{keep sparse}}
\]
solve under-determined linear system
we want the sparsest solution
\[
\min_{\alpha\in\mathbb{R}^{p}} \frac{1}{2} \lVert x - D\alpha \rVert^{2}_{2} + \underbrace{\psi(\alpha)}_{regularization}
\] 
measure sparsity via       l0-norm       ||a||0

Da=X
<>
In the last 15 years several sparse coding algorithms have been proposed. Some that solve the initial problem <> greedyly, the (orthogonal) matching pursuit, and others which modified the problem to become convex/linear. These primary derive from the numerical domain in the form of 
large linear system solvers with few optimization constraints. The LARS-Lasso, basis pursuit, FOCUSS?


blaa \footnote{test 123} blub

||a||0 makes the problem NP-hard
to get best solution you need to test every combination
Solution:
use greedy approach or 									make problem convex (e.g. use ||a||1)
\subsubsection{matching pursuit}
\begin{algorithmic}
\IF {$i\geq maxval$} 
        \STATE $i\gets 0$
\ELSE
        \IF {$i+k\leq maxval$}
                \STATE $i\gets i+k$
        \ENDIF
\ENDIF 
\end{algorithmic}

\subsubsection{orthogonal matching pursuit}
\label{sec:omp}
\begin{algorithm}
\caption{Wurst}
\begin{algorithmic}
\IF {$i\geq maxval$} 
        \STATE $i\gets 0$
\ELSE
        \IF {$i+k\leq maxval$}
                \STATE $i\gets i+k$
        \ENDIF
\ENDIF 
\end{algorithmic}

\subsubsection{LARS-Lasso}
\begin{algorithmic}
\IF {$i\geq maxval$} 
        \STATE $i\gets 0$
\ELSE
        \IF {$i+k\leq maxval$}
                \STATE $i\gets i+k$
        \ENDIF
\ENDIF 
\end{algorithmic}
\end{algorithm}

\section{Dictionaries/representation data}
\subsection{analytical}
\subsubsection{consine}
\subsubsection{wavelets}

\subsection{learned over-complete}
recent research has shown that learnd dictionaries show better compression quality than small analytic dictionaries \cite{Aharon2006KSVD} \cite{Chen1998Atomic} 


In the last decade several learning algorithms have been proposed which try to a universal basis that 
can sparsly reconstruct a set of "trainig data" with minimal error. 
K-SVD
MOD
Online learning
Mairal2010

\section{Learning for the Task}
It has been shown that learning basis specicial for certain tasks can lead to the best results\cite{}.  <>
Based on this discovery we will concentrate on a specific class. <> Join the basis for natural images and cartoon/line images.
We will also concentrate on real pratical data. This means typically 3-channel data of 1+ megapixel images found on image hosting services like flickr, twitpic, etc.

\section{Image database}

\section{Related work}
\subsection{denoising}
Remove noisy signal from image

\subsection{in-paiting}
fill missing parts by removing row from the dictionary

\subsection{better structure}

\subsubsection{multi-scale}
\subsubsection{multi-channel}
\subsubsection{hirarchy}
\subsubsection{training with a neural network}
Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\\
\url{http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}

\section{Goal}
Evaluate the quality and size of learned big redundant dictionaries for 
optimal sparse coding of large image databases.

what about a universal dictionary for natural images? 
how many elements for a 'good' sparse representation?
add structure for speed and model improvements
Multi-scale, multi-channel, hirarchy