\chapter{Overview}
%\thispagestyle{empty}
\numberwithin{equation}{chapter}

\section{Sparse signal representation}
\label{sec:dicts}
%\subsection{Problem statement}
Simplification of signals such as images, audio, video or EEG data is a major
field of signal processing. It can help to speed up operations on signals. Like
transformation or classification, and allows us to capture the most
significant basis elements that make up a signal. A basis that is
used in MP3 audio, JPEG images and MPEG4 video compression or to reconstruct
a signal in order to remove noise or recover missing information.

Consider $\tilde{x}$ a signal that is represent by a function $f(x)$ that
approximates
the signal $x$ in a simplified sparse way.
\begin{equation*}
x \sim \tilde{x} = f\left(x\right)
\end{equation*}
We are splitting $f(x)$ into a selection of elements from a large set
basis functions. In a sparse way, as the signal gets either represented with
a small selection of basis functions or analog as a series of many basis
functions where the majority of coefficients, that weight the function, are
close to zero. 
\begin{equation*}
\begin{split}
x \sim \tilde{x} & = b_{1}(x) + b_{12}(x) + b_{312}(x)\\
& = 0b_{1}(x) + \cdots + 1.1b_{2}(x) + 0.01b_{12}(x) + \cdots +
2b_{312}(x)
\end{split}
\end{equation*}
We call these basis functions $b_n$ \emph{atoms} as they are the basic units
which build up our representation of signals. So far, consider the actual
appearance of those function atoms as unknown. We organize all of them in a
indexed set called a \emph{dictionary} analog to a dictionary of words, where
the indices are the words and the atoms the description of them. 

%Active research in the last decades has shown that 
Dictionaries capture the essence of the signals that they represent.
A good basis or dictionary is essential for a good signal representation.

There are two major distinct ways to construct the desired dictionaries. First
the construction of model based on basis functions found via harmonic analysis
that can represent our signal in a sparse way or second via algorithms that find
or learn the atoms via a training process from a set of training signal samples.
The later approach of training good dictionaries has become a major task in the
last two decades\cite{Mairal2010}.


%Orthonormal (feature) vectors are orthogonal and have unit length.


\section{History}
\label{sec:history}
%Compressed sensing
The field of signal processing reaches far back in the early 60s.
\cite{Rubinstein2010}
In the early approaches in the 60s combinations of sine and cosine
transformations were used to approximate analog signals. For example the signal
could be represented via combinations of connected oscilloscopes with different
frequency configurations. Later on approximation of signals via combination of
limited signal samples became a major task in signal analysis.  The Fourier
transform is one of the most widely used ones. Signals get split into basis
functions that represent different signal frequencies 
Resulting a function of frequency $v$ t time $t$ and
\begin{equation*}
\mathcal{F}\left(v\right) = \int_{-\infty}^{\infty} \! f(t)e^{-i2\pi vt} \,
\mathrm{d}t
\end{equation*}
%Periodic signal in time represent as Several 
%application of such signal analysis and interpretation.

\paragraph{Getting discrete}
With the rise of the computer the term \emph{digital} entered the
game of signal processing. A move from continues signals of analog system to the
discrete representation common in the digital world, to utilize these new
powers, happed. Based on this move to digital signal processing new
approaches for basis transforms of discrete signals were required. The discrete
Fourier transform (DFT) emerged as as special discrete version of the continuous
Fourier transform.
\begin{equation*}
 x_k = \sum_{n=0}^{N-1}\alpha_ne^{\frac{-i2\pi kn}{N}}
\end{equation*}
In 1965 Cooley and Tukey presented\cite{Cooley1965} the \emph{fast Fourier
transform (FFT)} an fast algorithmic approach to calculation the discrete
Fourier transform. The fast Fourier transform is actual a reinvention of a
similar algorithm from 1805 by Carl Friedrich Gau√ü. The fast Fourier transform
was a major leap forward in the field of digital signal processing.

In the following decades two other major players in discrete basis
transformations emerged. The \emph{discrete cosine transform} and the
\emph{discrete wavelet transform}. 
The discrete cosine transformation (DCT) is a special case of the discrete
Fourier transform which only uses real part of the equation. The idea is to make
$f$ an odd function with $\forall x \in \mathbb{R} : f(x) = f(-x)$ which leads
to the imaginary part of the equation becoming zero.
\begin{equation*}
x_k = \sum_{n=0}^{N-1}\alpha_n\cos \left[ \frac{\pi}{N} \left(
n+\frac{1}{2}\right) k\right]
\end{equation*}
An example for the usage of DCT basis is the coding of the image blocks in the
JPEG image compression algorithm.

The discrete wavelet transformation (DWT)
Other than the DFTF and the DCT the wavelets transforms capture both frequency
and location information. 
 Property of the basis functions 
$\int_{-\infty}^{\infty} \! f(t) \, \mathrm{d}t = 0$
For example this locality property is used in JPEG 2000 image compression to
remove the block artifacts that occur in with DCT blocks in JPEG images
compression. 

In 80s the search for better transformation basis started to become a major role
in field of signal representation. Leading to basis such as Bandelets,
Curvelets, Contourlets, Wedgelets among others.

\paragraph{Splitting the problem}
\cite{Rubinstein2010}
In the last two decades (see\cite{Olshausen1996,Mallat1993}) a concept emerged
to interpret basis transforms as a set of discrete signal atoms in a dictionary
and the signals that they reconstruct as sparse linear combination of these
atoms. The benefit of this approach is that you can decouple signal coding and
dictionary design and split the whole process of signal analysis into two tasks.
First coding of signals and second the design of dictionaries. Separating the
problem into two distinct problems made the search for efficient coding of
signals $x$ and construction of task specific dictionaries $D$ more
flexible. The initial problem becomes:
\begin{equation}
 x  = D\alpha
\end{equation}
Or for better understanding in relation to the previously presented
equations.
\begin{equation}
x = \sum_{n=0}^{N-1}d_n\alpha_n\notag
\end{equation}

Ongoing research in this field emerged in order to:
\begin{itemize}
 \item Find efficient ways for coding signals in a sparse way.
 \item Design or learn a good dictionary that can code specific signal in sparse
way with low error.
\end{itemize}
%analog problem video compression but with less correlation between images and
%still image 
In computer vision applications for digital signal processing are for example
removing of image noise, image reconstruction and compression among.


\section{Goal of this thesis}
The main purpose of the thesis is to investigate the usability of dictionary
learning to learn dictionaries for large image databases. 
%that can be used for specific tasks on. 
In 2009 Mairal et al. of the Willow
Project\footnote{\url{http://www.di.ens.fr/willow/}} presented in
\cite{Mairal2009,Mairal2010} an online dictionary learning algorithm for sparse
coding. The presented algorithm enables us to learn dictionary elements from
large training sets found in large image databases.

They also released the Matlab framework \emph{SPArse Modeling Software}
short SPAMS\footnote{\url{http://www.di.ens.fr/willow/SPAMS/}} with all
necessary functions to recreate their results and experiment with the algorithm.
The problem is that the framework is closed source, which is impractical for
modifications like usage of different coding algorithms in the training process.
Also Matlab bears/includes some limitations that make it hard to test the
algorithms with big dictionaries.

To address these problems we reimplemented all necessary functions of the
framework in C++ to experiment with the applicability of sparse coding for
learning large dictionaries for large image databases. The three major steps of
the following chapters are:

\begin{itemize}
 \item Fast sparse coding of many small signals under different constraints
 \item Efficient learning redundant dictionaries for large image databases from
a large set of training data
 \item Evaluation of the quality and usage of the learned dictionaries
\end{itemize}

This includes topics like ``When do dictionaries different sizes and
learning configurations show convergence?'' ``How many atoms do we need for a
'good' sparse representation of large image databases?''  and ``How does this
affect quality and usability for certain application?''. 

\Todo{einbauen/conclusion?}
Better understanding the selection strategies of the algorithm and their
meaning for perceptional image quality. And evolution of the structure of
learned dictionaries. 

All these topics are addressed in several experiments. Experiments with
small sets specific images like from sketches, still images of animations from
Disney and art styles like post-impressionistic images from Vincent van Gogh.
Evaluation of the quality and size of learned big redundant dictionaries for
optimal sparse coding of large image databases. Search for a universal
dictionary for databases of hundredths of thousands of images. Evaluation of
clustering of learning algorithms. Application of sparse coding for image
compression and observation of problems. Such as encoding time, quality benefit.
Comparison of compression with discrete cosine transformation approaches in JPEG
and discrete wavelets transformation of JPEG 2000.
% and possible usage as an image descriptor.


%Convergence of the dictionary learning
%Quality increase with size increase 
%Comparison with JPEG,JPEG 2000 via MSE



%\Todo{OPTIONAL add structure for speed and model improvements Multi-scale, multi-channel, hierarchy}


